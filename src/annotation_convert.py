#!/usr/bin/env python3

#  a utility script to convert VGG annotations in a saved project json into mask images. 
#  INPUT:  journal images, annotation_names.csv (with label names),
#            annotation json generated by using labeling js
#            https://www.robots.ox.ac.uk/~vgg/software/via/via.html
#  OUTPUT: classes.txt and labels/ dir with color mask png images
import shutil

from dh_segment.io import via
import os
import sys
import pandas as pd
import numpy as np
from imageio import imsave, imread
import argparse

# base_dir = '../ufilm_dataset3'
# annotation_file = base_dir + '/via_project_3.json'
# masks_final_dir = base_dir + '/labels'
# masks_dir = masks_final_dir + '_tmp'
# # dir holding dirs named for file basename with b&w masks inside each dir
# masks_proto_dir = masks_dir + "/" + collection
# images_dir = base_dir + '/images'
# # one name per line, no header, keep order stable, only append to preserve existing color masks
# master_type_file = base_dir + '/annotation_names.csv'
# generated_classes_file = base_dir + "/classes.txt"
# the name of attribute (versus various values) defined in js annotation page/app
collection = 'training'  # subdir created to organize images, with sub-subdirs images, labels
attr_name = "label"  # earlier I used "type"

FLAGS = None
# init the parser
parser = argparse.ArgumentParser()

parser.add_argument(
    '--images_dir', '-i',
    type=str,
    default='../dataset_unknown',
    help='path to input images'
)
parser.add_argument(
    '--annotation_file', '-a',
    type=str,
    default='labeling/segment_labels.json',
    help='path vgg annotation project file'
)
FLAGS, unparsed = parser.parse_known_args()
if len(unparsed) > 0:
    print(f"  Unknown args: {unparsed}")
    sys.exit(1)
images_dir = FLAGS.images_dir
annotation_file = FLAGS.annotation_file
collection_dir = images_dir + '/' + collection
masks_final_dir = images_dir + '/' + collection + '/labels'    # color mask image files
images_final_dir = images_dir + '/' + collection + '/images'   # images will be moved here after processing
masks_dir = masks_final_dir + '_tmp'   # temp area for b&w masks
masks_proto_dir = masks_dir + "/" + collection
master_type_file = 'labeling/annotation_names.csv'  # ToDo: arg to specify this
generated_classes_file = images_dir + "/classes.txt"

"""
Expected input:
dataset_foo_journal/  contains:
 images, segment_labels.json, annotation_names.csv 

Expected results:
dataset_foo_journal/   contains:
  training/  
  training/images     ; images are moved to this created subdir  
  training/labels     ; label image masks 
  classes.txt         ; color to class mapping needed for training
  segment_labels.json
  annotation_names.csv

ToDo: need a way to auto-create ground.csv based on masks. 
"""

def create_blank_mask(input_image_filename, output_image_filename):
    # load image to get dimensions
    img = imread(input_image_filename)
    h = img.shape[0]
    w = img.shape[1]
    # create blank image
    out_img = np.zeros((h, w, 3))
    # save
    imsave(output_image_filename, out_img.astype(np.uint8))


# Load all the data in the annotation file
# (the file may be an exported project or an export of the annotations)
via_data = via.load_annotation_data(annotation_file)

# In the case of an exported project file, you can set ``only_img_annotations=True``
# to get only the image annotations
via_annotations = via.load_annotation_data(annotation_file, only_img_annotations=True)

# Collect the annotated regions
working_items = via.collect_working_items(via_annotations, collection, images_dir)

# Collect the attributes and options
if '_via_attributes' in via_data.keys():
    list_attributes = via.parse_via_attributes(via_data['_via_attributes'])
else:
    list_attributes = via.get_via_attributes(via_annotations)

# Create one mask per option per attribute
via.create_masks(masks_dir, working_items, list_attributes, collection)
# now we have images_dir / "labels_tmp" / "training" / "training_classes.txt"
#    and images_dir / "labels_tmp" / "training" / dir_named_after_image_basename
# NO dir for un-labeled images

# reference colors to use. 
hex_colors = ["#00FF00", "#0000FF", "#FF0000", "#01FFFE", "#FFA6FE", "#FFDB66", 
                    "#006401", "#010067", "#95003A", "#007DB5", "#FF00F6",
                    "#FFEEE8", "#774D00", "#90FB92", "#0076FF", "#D5FF00", "#FF937E", 
                    "#6A826C", "#FF029D", "#FE8900", "#7A4782", "#7E2DD2",
                    "#85A900", "#FF0056", "#A42400", "#00AE7E", "#683D3B", "#BDC6FF", 
                    "#263400", "#BDD393", "#00B917", "#9E008E", "#001544",
                    "#C28C9F", "#FF74A3", "#01D0FF", "#004754", "#E56FFE", "#788231", 
                    "#0E4CA1", "#91D0CB", "#BE9970", "#968AE8", "#BB8800",
                    "#43002C", "#DEFF74", "#00FFC6", "#FFE502", "#620E00", "#008F9C", 
                    "#98FF52", "#7544B1", "#B500FF", "#00FF78", "#FF6E41",
                    "#005F39", "#6B6882", "#5FAD4E", "#A75740", "#A5FFD2", "#FFB167", "#009BFF", "#E85EBE"]

rgb_colors = [tuple(int(h.lstrip("#")[i:i+2], 16) for i in (0, 2, 4)) for h in hex_colors]

#  microfilm_training-classes.txt is the raw classes file generated by the create_masks() above.   
gen_output_dir = masks_dir + '/' + collection
raw_classes_file = gen_output_dir + '/' + collection + '-classes.txt'

os.mkdir(masks_final_dir)
os.mkdir(images_final_dir)

# keep a master list of annotation types in annotation_names.csv so that if we add a new one, the 
# colors of existing color masks are still correct. We assign colors from rgb_colors in order of appears 
df = pd.read_csv(master_type_file, header=None)
df.columns = ['annotation_type']
annotation_type_series = df['annotation_type']
annotation_type_list = annotation_type_series.tolist()

# this is useful for multilabel, but not needed for classification
def emit_type_bits(outf, one_index, length):
    j = 0
    while j < sizeofList:
        if j == one_index:
            outf.write(" 1")
        else:
            outf.write(" 0")
        j = j + 1
    outf.write("\n")


sizeofList = len(annotation_type_list) 

# if generated_classes_file already exists, then overwrite

#  We want to map the annotation types to colors
out_file = open(generated_classes_file, "w")
# write out first line which represents no annotation at all for black
out_file.write("0 0 0\n") # black
# emit_type_bits(out_file, -1, sizeofList) # all zeros for annotation type combination
i=0
while i < sizeofList :
    annotation_type = annotation_type_list[i]
    rgb = rgb_colors[i]
    out_file.write(f"{rgb[0]} {rgb[1]} {rgb[2]}\n")
    # emit_type_bits(out_file, i, sizeofList)
    i = i + 1

out_file.close()

#
#   This file raw_classes_file generated by VGG (above) is not the same as dhSegment classes.txt ; 
#   Each line looks like:
#    sim_bjog_2011-01_118_2_0026	['type-footer', 'type-begin_article', 'type-page_num']
#   which is
#    file_basename ['type1', 'type2'...] 
#   we do not need to read this file since dir with b&w mask filenames contains all info we need to
#    make color masks.


#
#    For each example jpg or png, process corresponding png b&w masks created by VGG to make a composite color mask.
#      Each example training image has a directory name as basename. 
#      Inside that dir. are the b&w mask files in png format, each mask has same dimensions. 
#      A color_mask is created, all black. 
#      The white parts of a b&w mask correspond to color pixels associated with the attribute type of the mask
#        written to the color_mask, the attr. type is in the filename. 
#      The color mask is written to a labels/ directory as png.
basenames_processed = []
for basename in os.listdir(masks_proto_dir):
    if not os.path.isdir(masks_proto_dir + "/" + basename):
        continue
    color_mask = None
    basenames_processed.append(basename)
    for bnw_mask_name in os.listdir(masks_proto_dir + "/" + basename):
        # name has form ${BASENAME}-mask-type-${TYPE_NAME}.png
        annotation_type = bnw_mask_name.replace(basename + f"-mask-{attr_name}-", "").replace(".png", "")
        # read mask png, get dimensions
        bnw_mask_pixels = imread(masks_proto_dir + "/" + basename + "/" + bnw_mask_name)
        y,x = bnw_mask_pixels.shape  # gray scale, only 1 byte per pixel 
        # get color corresponding to annotation_type
        i = annotation_type_list.index(annotation_type)
        rgb = rgb_colors[i]
        if color_mask is None: 
            # create all black color_mask image same size as bnw_mask_name
            color_mask = np.zeros((y, x, 3))
        # b&w is grayscale, so white is 255, convert that to be 1 for next steps to be correct
        bnw_mask_pixels = bnw_mask_pixels/255
        # merge in the bnw grayscale image so that white parts become desired rgb 
        #  red
        color_mask[:,:,0] += rgb[0] * bnw_mask_pixels
        #  green
        color_mask[:,:,1] += rgb[1] * bnw_mask_pixels
        #  blue
        color_mask[:,:,2] += rgb[2] * bnw_mask_pixels
    # save the color_mask
    _ = sys.stdout.write(f"write mask {basename}.png\n")
    color_mask_8bit = color_mask.astype(np.uint8)
    imsave(masks_final_dir + "/" + basename + ".png", color_mask_8bit)


#
#   make blank (all black) masks for files that have no annotations
#
for image_file in os.listdir(images_dir):
    if not os.path.isfile(images_dir + "/" + image_file):
        continue
    if not (image_file.endswith(".png") or image_file.endswith(".jpg")):
        continue
    basename = os.path.basename(image_file)
    basename = os.path.splitext(basename)[0]
    if basename in basenames_processed:
        continue
    print(f"create blank mask {basename}")
    blank_mask_file = masks_final_dir + "/" + basename + ".png"
    create_blank_mask(images_dir + "/" + image_file, blank_mask_file)

#
#   move images to subdir
#
for image_file in os.listdir(images_dir):
    if not os.path.isfile(images_dir + "/" + image_file):
        continue
    if not (image_file.endswith(".png") or image_file.endswith(".jpg")):
        continue
    os.rename(images_dir + "/" + image_file, images_final_dir + "/" + image_file)

# remove temp area
shutil.rmtree(masks_dir)
